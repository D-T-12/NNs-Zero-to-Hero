{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1DVgLnQSSuFHVzjswQCTklfePgsVNggtP","authorship_tag":"ABX9TyMFxZBcW7dVOj/2vwZWMUCn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XkR3V0NWZ-oE"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["filepath = '/content/drive/MyDrive/ML Learning/edited_quotes.txt'\n","with open(filepath, 'r', encoding='utf-8') as f:\n","  text = f.read()"],"metadata":{"id":"y3CDlfZ1rBsn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(text[:1000])\n","print(len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM9ARqAIbZ7l","executionInfo":{"status":"ok","timestamp":1692166625557,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"cc50847d-e009-4e31-a901-183ca792e11e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.\n","You've gotta dance like there's nobody watching,Love like you'll never be hurt,Sing like there's nobody listening,And live like it's heaven on earth.\n","You know you're in love when you can't fall asleep because reality is finally better than your dreams.\n","A friend is someone who knows all about you and still loves you.\n","Darkness cannot drive out darkness: only light can do that. Hate cannot drive out hate: only love can do that.\n","We accept the love we think we deserve.\n","Only once in your life, I truly believe, you find someone who can completely turn your world around. You tell them things that youve never shared with another soul and they absorb everything you say and actually want to hear more. You share hopes for the future, dreams that will never come true, goals that were never achieved \n","99202206\n"]}]},{"cell_type":"code","source":["# The unique characters in the data\n","vocab = sorted(list(set(text)))\n","print(vocab)\n","\n","# The size of the vocab\n","vocab_size = len(vocab)\n","print('\\n')\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pf5nx4GusFqg","executionInfo":{"status":"ok","timestamp":1692166627661,"user_tz":-60,"elapsed":2108,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"8d2fd2f3-b33f-4352-c361-fd7ce78744b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n', ' ', '!', \"'\", '(', ')', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","\n","\n","75\n"]}]},{"cell_type":"code","source":["# Vocab Mapping with encoder and decoder\n","test = 'Hello World!'\n","deco_map = { count:values for count, values in enumerate(vocab)}\n","enco_map = { values:count for count, values in enumerate(vocab)}\n","encode = lambda e: [enco_map[x] for x in e]\n","decode = lambda d: ''.join(deco_map[y] for y in d)\n","\n","print(encode('This is encoding'))\n","print(decode(encode('Testing the decoder, 1234567890QWERTYUIOPASDFGHJKLZXCVBNMqwertyuiopasdfghjklzxcvbnm')))"],"metadata":{"id":"0XSjUq7un6Az","executionInfo":{"status":"ok","timestamp":1692166627662,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4838eba-457a-4cd9-a8f6-7a7a74554c44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[40, 56, 57, 67, 1, 57, 67, 1, 53, 62, 51, 63, 52, 57, 62, 55]\n","Testing the decoder, 1234567890QWERTYUIOPASDFGHJKLZXCVBNMqwertyuiopasdfghjklzxcvbnm\n"]}]},{"cell_type":"code","source":["# Encoding the dataset\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape)\n","print(data[:200])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpPnvdJaqvj6","executionInfo":{"status":"ok","timestamp":1692166646008,"user_tz":-60,"elapsed":18351,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"22aece90-93df-4fc3-cb58-b045594016f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([99202206])\n","tensor([29,  3, 61,  1, 67, 53, 60, 54, 57, 67, 56,  6,  1, 57, 61, 64, 49, 68,\n","        57, 53, 62, 68,  1, 49, 62, 52,  1, 49,  1, 60, 57, 68, 68, 60, 53,  1,\n","        57, 62, 67, 53, 51, 69, 66, 53,  7,  1, 29,  1, 61, 49, 59, 53,  1, 61,\n","        57, 67, 68, 49, 59, 53, 67,  6,  1, 29,  1, 49, 61,  1, 63, 69, 68,  1,\n","        63, 54,  1, 51, 63, 62, 68, 66, 63, 60,  1, 49, 62, 52,  1, 49, 68,  1,\n","        68, 57, 61, 53, 67,  1, 56, 49, 66, 52,  1, 68, 63,  1, 56, 49, 62, 52,\n","        60, 53,  7,  1, 22, 69, 68,  1, 57, 54,  1, 73, 63, 69,  1, 51, 49, 62,\n","         3, 68,  1, 56, 49, 62, 52, 60, 53,  1, 61, 53,  1, 49, 68,  1, 61, 73,\n","         1, 71, 63, 66, 67, 68,  6,  1, 68, 56, 53, 62,  1, 73, 63, 69,  1, 67,\n","        69, 66, 53,  1, 49, 67,  1, 56, 53, 60, 60,  1, 52, 63, 62,  3, 68,  1,\n","        52, 53, 67, 53, 66, 70, 53,  1, 61, 53,  1, 49, 68,  1, 61, 73,  1, 50,\n","        53, 67])\n"]}]},{"cell_type":"code","source":["# Splitting into train and dev\n","n = int(0.9*len(data))\n","train_data = data[:n]\n","dev_data = data[n:]"],"metadata":{"id":"OkEqRbG3v_18"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["block_size = 8\n","train_data[:block_size + 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DOS4H1FudV4g","executionInfo":{"status":"ok","timestamp":1692166646008,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"c5d823a2-1471-461f-8271-ab2b4a2c3fc9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([29,  3, 61,  1, 67, 53, 60, 54, 57])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","  context = x[:t+1]\n","  target = y[t]\n","  print(f'when the context is {context} the target is {target}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_O0PE7_Edp90","executionInfo":{"status":"ok","timestamp":1692166646009,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"52700401-f68c-4ae2-90d3-b13e8736e2b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["when the context is tensor([29]) the target is 3\n","when the context is tensor([29,  3]) the target is 61\n","when the context is tensor([29,  3, 61]) the target is 1\n","when the context is tensor([29,  3, 61,  1]) the target is 67\n","when the context is tensor([29,  3, 61,  1, 67]) the target is 53\n","when the context is tensor([29,  3, 61,  1, 67, 53]) the target is 60\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60]) the target is 54\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60, 54]) the target is 57\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4\n","block_size = 8\n","\n","def get_batch(split):\n","  # generate small batches of data for the model to train on\n","  data = train_data if split == 'train' else dev_data\n","  ix = torch.randint(len(data) - block_size, (batch_size, ))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  return x,y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","\n","print('----')\n","\n","for b in range(batch_size):\n","  for t in range(block_size):\n","    context = x[:t+1]\n","    target = y[t]\n","    print(f'when the context is {context} the target is {target}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZ_HOOH8eJYp","executionInfo":{"status":"ok","timestamp":1692166646522,"user_tz":-60,"elapsed":517,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"c12ceeae-85b4-4292-ce8e-8440405f19c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[53,  6,  1, 57, 68,  1, 67, 53],\n","        [49, 60, 60, 73,  1, 55, 66, 53],\n","        [56, 49, 70, 53,  1, 51, 63, 61],\n","        [ 1, 63, 50, 58, 53, 51, 68, 67]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[ 6,  1, 57, 68,  1, 67, 53, 53],\n","        [60, 60, 73,  1, 55, 66, 53, 49],\n","        [49, 70, 53,  1, 51, 63, 61, 53],\n","        [63, 50, 58, 53, 51, 68, 67,  1]])\n","----\n","when the context is tensor([29]) the target is 3\n","when the context is tensor([29,  3]) the target is 61\n","when the context is tensor([29,  3, 61]) the target is 1\n","when the context is tensor([29,  3, 61,  1]) the target is 67\n","when the context is tensor([29,  3, 61,  1, 67]) the target is 53\n","when the context is tensor([29,  3, 61,  1, 67, 53]) the target is 60\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60]) the target is 54\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60, 54]) the target is 57\n","when the context is tensor([29]) the target is 3\n","when the context is tensor([29,  3]) the target is 61\n","when the context is tensor([29,  3, 61]) the target is 1\n","when the context is tensor([29,  3, 61,  1]) the target is 67\n","when the context is tensor([29,  3, 61,  1, 67]) the target is 53\n","when the context is tensor([29,  3, 61,  1, 67, 53]) the target is 60\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60]) the target is 54\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60, 54]) the target is 57\n","when the context is tensor([29]) the target is 3\n","when the context is tensor([29,  3]) the target is 61\n","when the context is tensor([29,  3, 61]) the target is 1\n","when the context is tensor([29,  3, 61,  1]) the target is 67\n","when the context is tensor([29,  3, 61,  1, 67]) the target is 53\n","when the context is tensor([29,  3, 61,  1, 67, 53]) the target is 60\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60]) the target is 54\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60, 54]) the target is 57\n","when the context is tensor([29]) the target is 3\n","when the context is tensor([29,  3]) the target is 61\n","when the context is tensor([29,  3, 61]) the target is 1\n","when the context is tensor([29,  3, 61,  1]) the target is 67\n","when the context is tensor([29,  3, 61,  1, 67]) the target is 53\n","when the context is tensor([29,  3, 61,  1, 67, 53]) the target is 60\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60]) the target is 54\n","when the context is tensor([29,  3, 61,  1, 67, 53, 60, 54]) the target is 57\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","\n","class BigramLanguageModel(nn.Module):\n","\n","  def __init__(self, vocab_size):\n","    super().__init__()\n","    # each token directly reads off the logits for the next token from a lookup table\n","    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","  def forward(self, idx, targets=None):\n","\n","    logits = self.token_embedding_table(idx)\n","\n","    if targets is None:\n","      loss = None\n","    else:\n","      B, T, C = logits.shape\n","      logits = logits.view(B*T, C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","  def generate(self, idx, max_new_tokens):\n","    for _ in range(max_new_tokens):\n","      logits, loss = self(idx)\n","\n","      logits = logits[:, -1, :]\n","\n","      probs = F.softmax(logits, dim=-1)\n","\n","      idx_next = torch.multinomial(probs, num_samples=1)\n","\n","      idx = torch.cat((idx, idx_next), dim=1)\n","\n","    return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)"],"metadata":{"id":"OS0anyfUjdMT","executionInfo":{"status":"ok","timestamp":1692166646522,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e47ea3e1-f69e-4025-d889-2d44ecab9054"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 75])\n","tensor(4.9311, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqY-TmgujxPB","executionInfo":{"status":"ok","timestamp":1692166646523,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"489e91fb-af82-4c38-9c08-09817da14c87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","JlHwJ8kKZ1'GRak8iXaaO59n906gg8Eq ZVBImr9L..zZ\n","fzYfowYhE[O;WJ9VIc0VzQnF]X49w7C8'N8g\n","QLJ]Xe1A,\n","hNHjFHjdNng9cKbdlWOLEZdk?nHPTAzn5u?Kdl6CnDAniz6INAJx1JDFhToSVhg2]FlAL1bCYNMn k!5y(;X'Kn?zSaKTC.\n","fWhGbZyvWKjkp)nq4Dna2VAwTv]WJO;9Run92RDvvtHEbycEPJlL.Q30Q[;6iz?dX2?nC v6Y(eN'NVLdlsPmUWofw;c'JDPfH,Hj.8r0IJ6zTF6fPy!J8,.a\n","7\n","Kxb?1PK8rL?p!e6Yf'7h!]p09M(Is.CL!ITq;hG(w7vv]nex1u?:QrN'\n","v];XQ(k!S Kw)0,dQ?VnN:gA;h3e8S\n"]}]},{"cell_type":"code","source":["# Optimiser\n","optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"],"metadata":{"id":"Qk9Lj3wwphYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(10000):\n","\n","  xb, yb = get_batch('train')\n","\n","  logits, loss = m(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR-Hj50ksU1y","executionInfo":{"status":"ok","timestamp":1692166666823,"user_tz":-60,"elapsed":20303,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"a13f1e6a-7a4a-4f47-eeb6-0ad3f1475588"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.3351197242736816\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DeytfCpsoWg","executionInfo":{"status":"ok","timestamp":1692166666823,"user_tz":-60,"elapsed":19,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"5c745ab6-5d2a-4662-9352-02f4ccac0249"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","A tis nd aicur I whu d athid dous That treneay ticinth?Ne s))OI k'thaimingheveouthW:9006)verHeeiles I ougiroll Mntou mmasp brovicouruty henthericr kngicanioured wourerre Seicingag ORst. wit won l ing bo t be ou!\n","Anoutor, fDVI thevestor fove he(Oas ick, t bape alithe coreve tu d.Ace a grellde t WhadoverThe yond tikintrs atrove. isoLWed d s ou, bustoridaveat o Thing cyong benderoffo tal f y HXQg ahe\n"]}]},{"cell_type":"markdown","source":["Self attention maths trick\n","Get all the prevous letters to talk to the current prediction by averaging all previous letters."],"metadata":{"id":"aS75a4eHHrxH"}},{"cell_type":"code","source":["torch.manual_seed(1337)\n","B,T,C = 4,8,2\n","x = torch.randn(B,T,C)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0s7n9-HHpGn","executionInfo":{"status":"ok","timestamp":1692166666823,"user_tz":-60,"elapsed":17,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"382afe76-79a7-4917-a591-85b2f748dc15"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Inefficient way\n","xbow = torch.zeros((B,T,C))\n","for b in range(B):\n","  for t in range(T):\n","    xprev = x[b,:t+1]\n","    xbow[b,t] = torch.mean(xprev, 0)"],"metadata":{"id":"D4ERcEmwH4Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Version 2\n","wei = torch.tril(torch.ones(T,T))# Tril keeps the bottom triangle only of a matrix (see bellow)\n","wei = wei/wei.sum(1, keepdim=True)\n","xbow2 = wei @ x\n","torch.allclose(xbow, xbow2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRHRZWTdMIKw","executionInfo":{"status":"ok","timestamp":1692166666824,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"d649c9b2-9c32-4252-a4c7-b920508d6fe3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# Version 3: use softmax\n","tril = torch.tril(torch.ones(T,T)) # Tril keeps the bottom triangle only of a matrix\n","wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","xbow3 = wei @ x\n","torch.allclose(xbow, xbow3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUsqSQ1FLfOL","executionInfo":{"status":"ok","timestamp":1692166961521,"user_tz":-60,"elapsed":369,"user":{"displayName":"Ben Turner","userId":"11718061856028669146"}},"outputId":"d056429f-8e86-4205-dd9e-5930e60b86cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0.]])\n","tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# Version 4: self attention!\n","torch.manual_seed(1337)\n","B,T,C = 4,8,32\n","x = torch.randn(B,T,C)\n","\n","# Single head doing self attention\n","head_size = 16\n","value = nn.Linear(C, head_size, bias=False)\n","key = nn.Linear(C, head_size, bias=False)\n","query = nn.Linear(C, head_size, bias=False)\n","k = key(x)\n","q = query(x)\n","wei = q @ k.transpose(-2, -1)\n","\n","tril = torch.tril(torch.ones(T,T)) # Tril keeps the bottom triangle only of a matrix\n","# wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","wei = F.softmax(wei, dim=-1)\n","\n","v = value(x)\n","out = wei @ v\n"],"metadata":{"id":"-N5lcaGcDRqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ybwuxDPsFuW6"},"execution_count":null,"outputs":[]}]}